{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the uniprot ids of the HuRi data\n",
    "\n",
    "At the start of the project, a new HQ PPI dataset has been released (HuRi).\n",
    "\n",
    "https://www.nature.com/articles/s41586-020-2188-x <br>\n",
    "http://www.interactome-atlas.org/download\n",
    "\n",
    "There is a tsv file with only gene name combinations while we want the UniProtKB ids.\n",
    "There is also a PSI-MI file where more informations is stored.\n",
    "\n",
    "There is the github page on how to interpret the PSI-MI file:\n",
    "\n",
    "https://github.com/HUPO-PSI/miTab/blob/master/PSI-MITAB27Format.md\n",
    "\n",
    "This script tries to extract the UniProtIDs from the PSI-MI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import huri PSI-MI file\n",
    "df_huri = pd.read_csv('../Data/HuRi/HuRI_04_05_2020.psi', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uniprotkb:P0DP25</td>\n",
       "      <td>uniprotkb:A0A087WXN0</td>\n",
       "      <td>ensembl:ENST00000291295.13|ensembl:ENSP0000029...</td>\n",
       "      <td>ensembl:ENST00000612316.4|ensembl:ENSP00000481...</td>\n",
       "      <td>human orfeome collection:1(author assigned name)</td>\n",
       "      <td>human orfeome collection:56859(author assigned...</td>\n",
       "      <td>psi-mi:MI:1112(two hybrid prey pooling approach)</td>\n",
       "      <td>Luck et al.(2019)</td>\n",
       "      <td>unassigned1304</td>\n",
       "      <td>taxid:9606(Homo Sapiens)</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>gal4 dna binding domain:n-n (DB domain (n-term...</td>\n",
       "      <td>gal4 activation domain:n-n (AD domain (n-termi...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>psi-mi:MI1180(partial DNA sequence identificat...</td>\n",
       "      <td>psi-mi:MI1180(partial DNA sequence identificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniprotkb:Q68D86-1</td>\n",
       "      <td>uniprotkb:Q9HD26-2</td>\n",
       "      <td>ensembl:ENST00000360242.9|ensembl:ENSP00000353...</td>\n",
       "      <td>ensembl:ENST00000052569.10|ensembl:ENSP0000005...</td>\n",
       "      <td>human orfeome collection:54581(author assigned...</td>\n",
       "      <td>human orfeome collection:121(author assigned n...</td>\n",
       "      <td>psi-mi:MI:1112(two hybrid prey pooling approach)</td>\n",
       "      <td>Luck et al.(2019)</td>\n",
       "      <td>unassigned1304</td>\n",
       "      <td>taxid:9606(Homo Sapiens)</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>gal4 dna binding domain:n-n (DB domain (n-term...</td>\n",
       "      <td>gal4 activation domain:n-n (AD domain (n-termi...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>psi-mi:MI1180(partial DNA sequence identificat...</td>\n",
       "      <td>psi-mi:MI1180(partial DNA sequence identificat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0                     1   \\\n",
       "0    uniprotkb:P0DP25  uniprotkb:A0A087WXN0   \n",
       "1  uniprotkb:Q68D86-1    uniprotkb:Q9HD26-2   \n",
       "\n",
       "                                                  2   \\\n",
       "0  ensembl:ENST00000291295.13|ensembl:ENSP0000029...   \n",
       "1  ensembl:ENST00000360242.9|ensembl:ENSP00000353...   \n",
       "\n",
       "                                                  3   \\\n",
       "0  ensembl:ENST00000612316.4|ensembl:ENSP00000481...   \n",
       "1  ensembl:ENST00000052569.10|ensembl:ENSP0000005...   \n",
       "\n",
       "                                                  4   \\\n",
       "0   human orfeome collection:1(author assigned name)   \n",
       "1  human orfeome collection:54581(author assigned...   \n",
       "\n",
       "                                                  5   \\\n",
       "0  human orfeome collection:56859(author assigned...   \n",
       "1  human orfeome collection:121(author assigned n...   \n",
       "\n",
       "                                                 6                  7   \\\n",
       "0  psi-mi:MI:1112(two hybrid prey pooling approach)  Luck et al.(2019)   \n",
       "1  psi-mi:MI:1112(two hybrid prey pooling approach)  Luck et al.(2019)   \n",
       "\n",
       "               8                         9   ... 32 33 34 35  \\\n",
       "0  unassigned1304  taxid:9606(Homo Sapiens)  ...  -  -  -  -   \n",
       "1  unassigned1304  taxid:9606(Homo Sapiens)  ...  -  -  -  -   \n",
       "\n",
       "                                                  36  \\\n",
       "0  gal4 dna binding domain:n-n (DB domain (n-term...   \n",
       "1  gal4 dna binding domain:n-n (DB domain (n-term...   \n",
       "\n",
       "                                                  37 38 39  \\\n",
       "0  gal4 activation domain:n-n (AD domain (n-termi...  -  -   \n",
       "1  gal4 activation domain:n-n (AD domain (n-termi...  -  -   \n",
       "\n",
       "                                                  40  \\\n",
       "0  psi-mi:MI1180(partial DNA sequence identificat...   \n",
       "1  psi-mi:MI1180(partial DNA sequence identificat...   \n",
       "\n",
       "                                                  41  \n",
       "0  psi-mi:MI1180(partial DNA sequence identificat...  \n",
       "1  psi-mi:MI1180(partial DNA sequence identificat...  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_huri.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out PPIs from the test screens\n",
    "df_huri_no_test = df_huri[~df_huri[27].str.contains('test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort to filter redundant combinations\n",
    "df_uniprot_huri = pd.DataFrame(df_huri[[0, 1]].apply(lambda x: sorted(x), axis=1).to_list())\n",
    "df_uniprot_huri_no_test = pd.DataFrame(df_huri_no_test[[0, 1]].apply(lambda x: sorted(x), axis=1).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter redundant combinations\n",
    "df_uniprot_comb = df_uniprot_huri.drop_duplicates()\n",
    "df_uniprot_comb_no_test = df_uniprot_huri_no_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper PPI claim: 52569\n",
      "PSI-MI PPIs number: 52929\n",
      "PSI-MI PPIs number without test results: 52237\n"
     ]
    }
   ],
   "source": [
    "# Now something weird is happening. \n",
    "# The numbers do not match with the papers claim. \n",
    "print('The paper PPI claim: 52569')\n",
    "print('PSI-MI PPIs number:', len(df_uniprot_comb))\n",
    "print('PSI-MI PPIs number without test results:', len(df_uniprot_comb_no_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if we can find the reason using the other tsv file HuRi provides on the website\n",
    "# This file only contains the ENSG id of interactor A and B\n",
    "\n",
    "# load the ENSG data\n",
    "df_huri_ensg =  pd.read_csv('../Data/HuRi/HuRI_genes_04_05_2020.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuRi gene combination number: 52548\n"
     ]
    }
   ],
   "source": [
    "# the numebr of combinations doesnt match the paper, but maybe there are redundant gene combinations\n",
    "# due to splice variation\n",
    "df_huri_ensg = pd.DataFrame(df_huri_ensg[[0, 1]].apply(lambda x: sorted(x), axis=1).to_list())\n",
    "print('HuRi gene combination number:', len(df_huri_ensg.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ensembl:ENST00000380750.7|ensembl:ENSP00000370126.3|ensembl:ENSG00000205572.9|ensembl:ENST00000354833.7|ensembl:ENSP00000346892.3|ensembl:ENSG00000172058.15'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is annoying since we now need the ENSG mapping of the Uniprot id\n",
    "# to figure out why we have less PPIs than the paper claims.\n",
    "# The ENSG ids of each interactor are in the PSI file but apparently\n",
    "# some of UniProt ids map to multiple ENSG ids.\n",
    "df_huri_no_test.iloc[113,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple ENSG ids column 2? True\n"
     ]
    }
   ],
   "source": [
    "# prove that there can multiple ENSGs in one cell\n",
    "# if the split list length is greater than 2, multiple ENSGs are found\n",
    "check_one_ensg_id = lambda x: len(x.split('ENSG')) > 2\n",
    "print('multiple ENSG ids column 2?', True in df_huri[2].apply(check_one_ensg_id).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with multiple ENSG ids: 903\n"
     ]
    }
   ],
   "source": [
    "#now see how many rows have multiple ENSGs in one of the two columns\n",
    "df_multiple_ensg = df_huri_no_test[df_huri_no_test[2].apply(check_one_ensg_id) | \n",
    "                                   df_huri_no_test[3].apply(check_one_ensg_id)]\n",
    "print('Number of entries with multiple ENSG ids:', len(df_multiple_ensg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple UniProt ids column 0? False\n",
      "multiple UniProt ids column 1? False\n"
     ]
    }
   ],
   "source": [
    "# They have max one uniprot mapping\n",
    "check_multiple_uniprot_ids = lambda x: len(x.split('uniprotkb')) > 2\n",
    "print('multiple UniProt ids column 0?', True in df_huri[0].apply(check_multiple_uniprot_ids).unique())\n",
    "print('multiple UniProt ids column 1?', True in df_huri[1].apply(check_multiple_uniprot_ids).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just try to create all possible combinations of ENSG ids to see\n",
    "# if this number matches the tsv file. \n",
    "\n",
    "list_of_genes_A = df_huri_no_test[2].apply(\n",
    "                            lambda x: [i[i.find(':')+1:] for i in x.split('|')[2::3]]\n",
    "                ).to_list()\n",
    "\n",
    "list_of_genes_B = df_huri_no_test[3].apply(\n",
    "                            lambda x: [i[i.find(':')+1:] for i in x.split('|')[2::3]]\n",
    "                ).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows is the PSI file: 167924\n",
      "Possible ENSG id combinations with redundancy: 168956\n"
     ]
    }
   ],
   "source": [
    "#create a list with tuples of all combinations of ESNG ids and sort the tuples\n",
    "all_combinations = [list(itertools.product(a, b)) for a,b in zip(list_of_genes_A,list_of_genes_B)]\n",
    "all_combinations_list = [tuple(sorted(x)) for x in itertools.chain.from_iterable(all_combinations)]\n",
    "\n",
    "print('Total rows is the PSI file:', len(df_huri_no_test))\n",
    "print('Possible ENSG id combinations with redundancy:', len(all_combinations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ENSG id combinations from tsv: 52548\n",
      "Unique ENSG id combinations from PSI: 52548\n"
     ]
    }
   ],
   "source": [
    "#So there it is our number, it matches :D\n",
    "# Now we now where the ENSG combination number comes from is the tsv file.\n",
    "\n",
    "print('Unique ENSG id combinations from tsv:', len(df_huri_ensg.drop_duplicates()))\n",
    "print('Unique ENSG id combinations from PSI:', len(set(all_combinations_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every row in the HuRi PSI-MI file has one uniprot id for each interactor\n",
    "# The number of unique uniprot id combinations is lower than the paper claims so that is weird\n",
    "# Maybe they used all unique combination of ENSP to get to this number?\n",
    "\n",
    "list_of_proteins_A = df_huri_no_test[2].apply(\n",
    "                            lambda x: [i[i.find(':')+1:] for i in x.split('|')[1::3]]\n",
    "                ).to_list()\n",
    "\n",
    "list_of_proteins_B = df_huri_no_test[3].apply(\n",
    "                            lambda x: [i[i.find(':')+1:] for i in x.split('|')[1::3]]\n",
    "                ).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list with tuples of all combinations of ENSP ids and sort the tuples\n",
    "all_comb_prot = [list(itertools.product(a, b)) for a,b in zip(list_of_proteins_A,list_of_proteins_B)]\n",
    "all_comb_prot_list = [tuple(sorted(x)) for x in itertools.chain.from_iterable(all_comb_prot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame with unique ENSP combinations\n",
    "ensp_comb_huri_final = pd.DataFrame(all_comb_prot_list).drop_duplicates()\n",
    "# remove version number\n",
    "ensp_comb_huri_final.iloc[:,0] = ensp_comb_huri_final.iloc[:,0].apply(lambda x: x.split('.')[0])\n",
    "ensp_comb_huri_final.iloc[:,1] = ensp_comb_huri_final.iloc[:,1].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper PPIs claim: 52569\n",
      "Unique protein combinations using ESPN ids from PSI_MI: 52549\n"
     ]
    }
   ],
   "source": [
    "# Nope, it's not the number we are looking for\n",
    "# We are somehow missing 20 PPIs\n",
    "print('Paper PPIs claim: 52569')\n",
    "print('Unique protein combinations using ESPN ids from PSI_MI:', len(ensp_comb_huri_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how many uniprot id combinations we can actually make. \n",
    "# All combinations where at least one of the two id's is not UniProt are filtered out.\n",
    "uniprot_comb_huri_final = df_uniprot_comb_no_test[df_uniprot_comb_no_test\\\n",
    "                                            .apply(lambda x: all('uniprotkb' in i for i in x), axis=1)]\n",
    "# remove 'uniprot:' in value\n",
    "uniprot_comb_huri_final.iloc[:,0] = uniprot_comb_huri_final.iloc[:,0].apply(lambda x: x.split(':')[1])\n",
    "uniprot_comb_huri_final.iloc[:,1] = uniprot_comb_huri_final.iloc[:,1].apply(lambda x: x.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper PPIs claim: 52569\n",
      "Unique protein combinations using UniProt ids from PSI_MI: 51373\n",
      "Unique protein combinations using ENSP ids from PSI_MI: 52549\n"
     ]
    }
   ],
   "source": [
    "print('Paper PPIs claim: 52569')\n",
    "print('Unique protein combinations using UniProt ids from PSI_MI:', len(uniprot_comb_huri_final))\n",
    "print('Unique protein combinations using ENSP ids from PSI_MI:', len(ensp_comb_huri_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique UniProt ids: 8148\n",
      "Number of unique ENSP ids: 8274\n"
     ]
    }
   ],
   "source": [
    "# ENSP and UniProt have the different numbers of unique ids\n",
    "all_unique_uniprot_ids = pd.Series(pd.concat([uniprot_comb_huri_final[0],uniprot_comb_huri_final[1]]).unique())\n",
    "all_unique_ensp_ids = pd.Series(pd.concat([ensp_comb_huri_final[0],ensp_comb_huri_final[1]]).unique())\n",
    "\n",
    "print('Number of unique UniProt ids:', len(all_unique_uniprot_ids))\n",
    "print('Number of unique ENSP ids:', len(all_unique_ensp_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT\n",
    "From this point on I accept that we are missing 20 PPIs. The number of gene combinations matches the gene combination tsv file. When I use the same method to get all unique protein ENSP id combination, the number of unique combinations is 20 less than expected.\n",
    "\n",
    "There are now two things we can do:\n",
    "\n",
    "1. Use the UniProt id combinations. This means that we have 51373 PPIs (1196 less than the paper claims).<br>\n",
    "2. Use the ENSP id combinations. This means that we have 52549 PPIs (20 less than the paper claims)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8274\n",
      "8274\n"
     ]
    }
   ],
   "source": [
    "uniprot_comb_huri_final.to_csv('../Data/Interactome/uniprot_ids_unique_combinations_huri.csv',\n",
    "                               header=False, index=False)\n",
    "ensp_comb_huri_final.to_csv('../Data/Interactome/ensp_ids_unique_combinations_huri.csv',\n",
    "                               header=False, index=False)\n",
    "\n",
    "all_unique_uniprot_ids.to_csv('../Data/Interactome/all_unique_uniprot_ids.csv',\n",
    "                               header=False, index=False)\n",
    "all_unique_ensp_ids.to_csv('../Data/Interactome/all_unique_ensp_ids.csv',\n",
    "                               header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
