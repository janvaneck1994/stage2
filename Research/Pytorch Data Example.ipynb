{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import torch\n",
    "import networkx as nx\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops,\n",
    "                                   add_self_loops)\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv, GATConv, ECConv  # noqa\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import SAGEConv, SplineConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist('../Data/Interactome/huri_apid_merge_ppis_edgelist.csv')\n",
    "embeddings = np.load('../Data/embeddings/embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist = [x for x in G.nodes() if x in embeddings.keys()]\n",
    "G = nx.Graph(G.subgraph(nodelist))\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "nodemapping = {x:int(i) for i,x in enumerate(nodelist)}\n",
    "embeddings_matrix = np.array([embeddings[x] for x in nodelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix2 = np.ones((len(nodelist),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = nx.relabel_nodes(G, nodemapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_edges = np.array(list(H.edges(nbunch=nodemapping.values()))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(index_edges.T, dtype=torch.long)\n",
    "x = torch.tensor(embeddings_matrix, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index)\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data, val_ratio=0.00, test_ratio=0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test = data.test_pos_edge_index\n",
    "neg_test = data.test_neg_edge_index\n",
    "train_pos = data.train_pos_edge_index\n",
    "\n",
    "pos_neg = []\n",
    "train_edges = []\n",
    "for x in range(2):\n",
    "    train_edges.append([nodelist[i] for i in train_pos[x]] + [nodelist[i] for i in train_pos[x]])\n",
    "    pos_neg.append([nodelist[i] for i in pos_test[x]] + [nodelist[i] for i in neg_test[x]])\n",
    "\n",
    "pos_neg = np.array(pos_neg).T\n",
    "train_edges = list(set(np.array(train_edges).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mmseq = pd.read_csv('../Data/mmseqs/align.m8', sep='\\t', header=None)\n",
    "more_40_seq_id = df_mmseq[df_mmseq[2] > 0.4]\n",
    "node_sim_dict = {}\n",
    "for x in more_40_seq_id[[0,1]].values:\n",
    "    if x[0] not in node_sim_dict.keys():\n",
    "        node_sim_dict[x[0]] = [x[0]]\n",
    "    if x[1] not in node_sim_dict.keys():\n",
    "        node_sim_dict[x[1]] = [x[1]]\n",
    "\n",
    "    node_sim_dict[x[0]].append(x[1])\n",
    "    node_sim_dict[x[1]].append(x[0])\n",
    "\n",
    "node_sim_dict = {x:list(set(y)) for x,y in node_sim_dict.items()}\n",
    "\n",
    "sim_train_nodes = []\n",
    "for x in train_edges:\n",
    "    if x in node_sim_dict.keys():\n",
    "        sim_train_nodes = sim_train_nodes + node_sim_dict[x]\n",
    "    else:\n",
    "        sim_train_nodes = sim_train_nodes + [x]\n",
    "\n",
    "sim_train_nodes = list(set(sim_train_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_c1 = []\n",
    "idx_c2 = []\n",
    "idx_c3 = []\n",
    "\n",
    "for i, x in enumerate(pos_neg):\n",
    "    if x[0] in sim_train_nodes and x[1] in sim_train_nodes:\n",
    "        idx_c1.append(i)\n",
    "    elif x[0] not in sim_train_nodes and x[1] not in sim_train_nodes:\n",
    "        idx_c3.append(i)   \n",
    "    else:\n",
    "        idx_c2.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428094786/work/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78083.0 5275.0 112.0\n",
      "Epoch: 001, Loss: 0.6783, Test C1: 0.8524, Test C2: 0.7749, Test C3: 0.6151\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 206.00 MiB (GPU 0; 3.95 GiB total capacity; 1.48 GiB already allocated; 216.69 MiB free; 1.80 GiB reserved in total by PyTorch) (malloc at /opt/conda/conda-bld/pytorch_1587428094786/work/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x4e (0x7fe0b052bb5e in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1f39d (0x7fe0b02ed39d in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x2058e (0x7fe0b02ee58e in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #3: THCStorage_resize + 0x96 (0x7fe06a1a7686 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: at::native::(anonymous namespace)::resize_cuda_(at::Tensor&, c10::ArrayRef<long>, c10::optional<c10::MemoryFormat>) + 0x799 (0x7fe06bcdd879 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0x2a0e253 (0x7fe06bcde253 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0xd84292 (0x7fe06a054292 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #7: <unknown function> + 0xeb735f (0x7fe06a18735f in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #8: at::native::bmm_cuda(at::Tensor const&, at::Tensor const&) + 0x9 (0x7fe06b8d79b9 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: <unknown function> + 0xdd7ac8 (0x7fe06a0a7ac8 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #10: <unknown function> + 0xe224d0 (0x7fe0910a74d0 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x288634c (0x7fe092b0b34c in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0xe224d0 (0x7fe0910a74d0 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: at::Tensor c10::Dispatcher::callUnboxed<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::OperatorHandle const&, at::Tensor const&, at::Tensor const&) const + 0xb3 (0x7fe0b0b9ada3 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #14: at::Tensor::bmm(at::Tensor const&) const + 0x4c (0x7fe0928f258c in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::generated::BmmBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1b7 (0x7fe09288c847 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: <unknown function> + 0x2ae8215 (0x7fe092d6d215 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7fe092d6a513 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #18: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7fe092d6b2f2 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::Engine::thread_init(int) + 0x39 (0x7fe092d63969 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #20: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7fe0b0e5e9f8 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #21: <unknown function> + 0xc819d (0x7fe0cca0b19d in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #22: <unknown function> + 0x9609 (0x7fe0cfb0d609 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #23: clone + 0x43 (0x7fe0cfa34103 in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b79e224485f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mbest_val_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mtest_c1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_c2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_c3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b79e224485f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 206.00 MiB (GPU 0; 3.95 GiB total capacity; 1.48 GiB already allocated; 216.69 MiB free; 1.80 GiB reserved in total by PyTorch) (malloc at /opt/conda/conda-bld/pytorch_1587428094786/work/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x4e (0x7fe0b052bb5e in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1f39d (0x7fe0b02ed39d in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x2058e (0x7fe0b02ee58e in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #3: THCStorage_resize + 0x96 (0x7fe06a1a7686 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: at::native::(anonymous namespace)::resize_cuda_(at::Tensor&, c10::ArrayRef<long>, c10::optional<c10::MemoryFormat>) + 0x799 (0x7fe06bcdd879 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0x2a0e253 (0x7fe06bcde253 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0xd84292 (0x7fe06a054292 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #7: <unknown function> + 0xeb735f (0x7fe06a18735f in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #8: at::native::bmm_cuda(at::Tensor const&, at::Tensor const&) + 0x9 (0x7fe06b8d79b9 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: <unknown function> + 0xdd7ac8 (0x7fe06a0a7ac8 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #10: <unknown function> + 0xe224d0 (0x7fe0910a74d0 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x288634c (0x7fe092b0b34c in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0xe224d0 (0x7fe0910a74d0 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: at::Tensor c10::Dispatcher::callUnboxed<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::OperatorHandle const&, at::Tensor const&, at::Tensor const&) const + 0xb3 (0x7fe0b0b9ada3 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #14: at::Tensor::bmm(at::Tensor const&) const + 0x4c (0x7fe0928f258c in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::generated::BmmBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1b7 (0x7fe09288c847 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: <unknown function> + 0x2ae8215 (0x7fe092d6d215 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7fe092d6a513 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #18: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7fe092d6b2f2 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::Engine::thread_init(int) + 0x39 (0x7fe092d63969 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #20: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7fe0b0e5e9f8 in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #21: <unknown function> + 0xc819d (0x7fe0cca0b19d in /home/jan-van-eck/anaconda3/envs/GNN/lib/python3.8/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #22: <unknown function> + 0x9609 (0x7fe0cfb0d609 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #23: clone + 0x43 (0x7fe0cfa34103 in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(1024, 1024)\n",
    "        self.lin1 = torch.nn.Linear(1024, 1024)\n",
    "        self.conv2 = GCNConv(1024, 1024)\n",
    "        self.lin2 = torch.nn.Linear(1024, 1024)\n",
    "#         self.conv3 = GCNConv(1024, 1024)\n",
    "#         self.lin3 = torch.nn.Linear(1024, 1024)\n",
    "\n",
    "        self.lin4 = torch.nn.Linear(2048, 1024)\n",
    "        self.lin5 = torch.nn.Linear(1024, 512)\n",
    "#         self.lin6 = torch.nn.Linear(128, 1)\n",
    "#         self.lin2 = torch.nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, pos_edge_index, neg_edge_index):\n",
    "\n",
    "        x1 = F.elu(self.conv1(data.x, data.train_pos_edge_index)+ self.lin1(data.x))\n",
    "        x1 = F.dropout(x1, p=0.5, training=self.training)\n",
    "        x2 = F.elu(self.conv2(x1, data.train_pos_edge_index)+ self.lin2(data.x))\n",
    "        x2 = F.dropout(x2, p=0.5, training=self.training)\n",
    "\n",
    "#         x = F.elu(self.conv2(x, data.train_pos_edge_index)+ self.lin2(x)) \n",
    "#         x = F.elu(self.conv3(x, data.train_pos_edge_index)+ self.lin3(x))\n",
    "        x = torch.cat([x1, x2], dim=-1)\n",
    "\n",
    "        x = F.elu(self.lin4(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = F.elu(self.lin5(x))\n",
    "#         x = F.elu(self.lin6(x))\n",
    "        \n",
    "        total_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)\n",
    "        x_j = torch.index_select(x, 0, total_edge_index[0])\n",
    "        x_i = torch.index_select(x, 0, total_edge_index[1])\n",
    "        return torch.einsum(\"ef,ef->e\", x_i, x_j)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    link_labels = torch.zeros(pos_edge_index.size(1) +\n",
    "                              neg_edge_index.size(1)).float().to(device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x, pos_edge_index = data.x, data.train_pos_edge_index\n",
    "\n",
    "    _edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "    pos_edge_index_with_self_loops, _ = add_self_loops(_edge_index,\n",
    "                                                       num_nodes=x.size(0))\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=pos_edge_index_with_self_loops, num_nodes=x.size(0),\n",
    "        num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "    link_logits = model(pos_edge_index, neg_edge_index)\n",
    "    link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    perfs = []\n",
    "    for prefix in [\"test\"]:\n",
    "        pos_edge_index, neg_edge_index = [\n",
    "            index for _, index in data(\"{}_pos_edge_index\".format(prefix),\n",
    "                                       \"{}_neg_edge_index\".format(prefix))\n",
    "        ]\n",
    "        link_probs = torch.sigmoid(model(pos_edge_index, neg_edge_index))\n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "        link_probs = link_probs.detach().cpu().numpy()\n",
    "        link_labels = link_labels.detach().cpu().numpy()\n",
    "        perfs.append(roc_auc_score(link_labels[idx_c1], link_probs[idx_c1]))\n",
    "        perfs.append(roc_auc_score(link_labels[idx_c2], link_probs[idx_c2]))\n",
    "        perfs.append(roc_auc_score(link_labels[idx_c3], link_probs[idx_c3]))\n",
    "        print(sum(link_labels[idx_c1]),sum(link_labels[idx_c2]),sum(link_labels[idx_c3]))\n",
    "\n",
    "    return perfs\n",
    "\n",
    "\n",
    "best_val_perf = test_perf = 0\n",
    "for epoch in range(1, 501):\n",
    "    train_loss = train()\n",
    "    test_c1, test_c2, test_c3 = test()\n",
    " \n",
    "    log = 'Epoch: {:03d}, Loss: {:.4f}, Test C1: {:.4f}, Test C2: {:.4f}, Test C3: {:.4f}'\n",
    "    print(log.format(epoch, train_loss, test_c1, test_c2, test_c3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
